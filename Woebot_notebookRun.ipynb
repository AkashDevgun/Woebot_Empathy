{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/akashdevgun/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda Available: True\n"
     ]
    }
   ],
   "source": [
    "# Importing Main Libraries\n",
    "import torch\n",
    "\n",
    "torch.cuda.current_device()\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from preprocess_load_embedding import EmpathyDataset, DataPreprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.backends.cudnn as cudnn\n",
    "from models_LSTMs import LSTM_fixed_len, LSTM_variable_input, LSTM_glove_vecs\n",
    "from train_test_lossCriterion import train, get_optimizer_criterion_scheduler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(1)\n",
    "\n",
    "# Model was trained using GPU in CUDA Environment\n",
    "print(\"Cuda Available: {}\".format(torch.cuda.is_available()))\n",
    "\n",
    "# File Names\n",
    "labelled_message_file = \"/media/HDD_2TB.1/machine-learning-engineer/labeled_messages.csv\"\n",
    "empathies_file = \"/media/HDD_2TB.1/machine-learning-engineer/empathies.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that calls to train different types of LSTMs\n",
    "def train_lstms(model, num_epochs, learning_rate, loss_weights, device, train_queue, valid_queue):\n",
    "    model = model.to(device)\n",
    "    criterion, optimizer, scheduler = get_optimizer_criterion_scheduler(model, num_epochs, learning_rate,\n",
    "                                                                        loss_weights, device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        scheduler.step()\n",
    "        train(model, device, train_queue, valid_queue, optimizer, epoch, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Method\n",
    "def main():\n",
    "    # Object 'Data' is created by Class Named -> 'DataPreprocessing' with file names as parameters\n",
    "    data = DataPreprocessing(labelled_message_file, empathies_file)\n",
    "\n",
    "    # Method Call describes number of words in Corpus, messages lengths\n",
    "    data.describe_counts()\n",
    "\n",
    "    # Method call for MultiLabel Encoding, for weighted label weights to handle imbalance\n",
    "    output_size, loss_weights = data.label_binarizer_get_weights()\n",
    "\n",
    "    # CAll to Get X and Y\n",
    "    X = data.get_X_data()\n",
    "    y = data.get_Y_data()\n",
    "    print('\\n')\n",
    "\n",
    "    # Train and Test Split\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # Baseline Classifier using SVC to calculate Accuracy and Area Under Curve Scores\n",
    "    print(\"***** Baseline AUC Scores *****\")\n",
    "    acc_svm, roc_svm = data.modelling(\"SVC\", X_train, X_valid, y_train, y_valid)\n",
    "    print(\"SVM Modelling --> Validation Acc. : %.3f, Validation AUC Score : %.3f\" % (acc_svm, roc_svm))\n",
    "    acc_RF, roc_RF = data.modelling(\"RandomForest\", X_train, X_valid, y_train, y_valid)\n",
    "\n",
    "    print(\"***** Statistical Method better then Baseline *****\")\n",
    "    # Baseline Classifier using SVC to calculate Accuracy and Area Under Curve Scores\n",
    "    print(\"Random Forest Modelling --> Validation Acc. : %.3f, Validation AUC Score : %.3f\" % (acc_RF, roc_RF))\n",
    "\n",
    "    # Class 'EmpathyDataset' Called for train and valid dataset to load while run time during training and testing\n",
    "    train_ds = EmpathyDataset(X_train, y_train)\n",
    "    valid_ds = EmpathyDataset(X_valid, y_valid)\n",
    "\n",
    "    vocab_size = len(data.words)\n",
    "    num_epochs = 1001\n",
    "    batch_size = 1000\n",
    "    learning_rate = 0.3\n",
    "\n",
    "    # Data Loader for train and test\n",
    "    train_queue = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    valid_queue = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # CUDA Environment Settings\n",
    "    torch.cuda.set_device(0)\n",
    "    cudnn.benchmark = True\n",
    "    torch.manual_seed(1)\n",
    "    cudnn.enabled = True\n",
    "    torch.cuda.manual_seed(1)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    # LSTMs models with fixed length Input, variable length Input, using StandFord Glove Representations\n",
    "    print('\\n')\n",
    "    print('-----------LSTMs Fixed Length Input--------------')\n",
    "    model1 = LSTM_fixed_len(vocab_size, 48, 96, output_size)\n",
    "    train_lstms(model1, num_epochs, learning_rate, loss_weights, device, train_queue, valid_queue)\n",
    "\n",
    "    print('\\n')\n",
    "    print('-----------LSTMs Variable Length Input--------------')\n",
    "    model2 = LSTM_variable_input(vocab_size, 48, 96, output_size)\n",
    "    train_lstms(model2, num_epochs, learning_rate, loss_weights, device, train_queue, valid_queue)\n",
    "\n",
    "    print('\\n')\n",
    "    print('-----------LSTMs with Glove Representation of Input--------------')\n",
    "    word_vecs = data.load_glove_vectors()\n",
    "    pretrained_weights, vocab, vocab2index = data.get_emb_matrix(word_vecs)\n",
    "    model3 = LSTM_glove_vecs(vocab_size, 50, 96, pretrained_weights, output_size)\n",
    "    train_lstms(model3, num_epochs, learning_rate, loss_weights, device, train_queue, valid_queue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (3562, 4)\n",
      "First 5 Columns of Data:\n",
      "   num_seen          message       empathy ignore\n",
      "0      2884            tired         tired    NaN\n",
      "1       253        exhausted         tired    NaN\n",
      "2        61          drained         tired    NaN\n",
      "3        31  tired but happy  tired, happy    NaN\n",
      "4        30         im tired         tired    NaN\n",
      "\n",
      "\n",
      "Number of words in Corpus: 2114\n",
      "Message Avg Length : 5.123526108927569, Message Max Length : 121\n",
      "Number of Empathies: 62, Output Shape is: (3562, 62)\n",
      "\n",
      "\n",
      "First 5 Columns of Data After Preprocessing and MultiLabel Encoding:\n",
      "   num_seen          message       empathy  message_length  \\\n",
      "0      2884            tired         tired               1   \n",
      "1       253        exhausted         tired               1   \n",
      "2        61          drained         tired               1   \n",
      "3        31  tired but happy  tired, happy               3   \n",
      "4        30       i am tired         tired               3   \n",
      "\n",
      "                                             encoded       y_encoded  \\\n",
      "0  [[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...         [tired]   \n",
      "1  [[3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...         [tired]   \n",
      "2  [[4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...         [tired]   \n",
      "3  [[2, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  [tired, happy]   \n",
      "4  [[7, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...         [tired]   \n",
      "\n",
      "                                       y_encoded_int  \n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "***** Baseline AUC Scores *****\n",
      "SVM Modelling --> Validation Acc. : 0.972, Validation AUC Score : 0.606\n",
      "***** Statistical Method better then Baseline *****\n",
      "Random Forest Modelling --> Validation Acc. : 0.892, Validation AUC Score : 0.685\n",
      "\n",
      "\n",
      "-----------LSTMs Fixed Length Input--------------\n",
      "Epoch: 1, Train loss: 0.676, Val loss: 0.668, Val Acc: 0.621, Val AUC_ROC Macro: 0.488, Val AUC_ROC Weighted : 0.488, Val Recall Macro: 0.474, Val Precision Weighted : 0.955, Val Ham Loss : 0.379\n",
      "Epoch: 101, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.634, Val AUC_ROC Weighted : 0.634, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 201, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.677, Val AUC_ROC Weighted : 0.677, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 301, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.695, Val AUC_ROC Weighted : 0.695, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 401, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.704, Val AUC_ROC Weighted : 0.704, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 501, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.706, Val AUC_ROC Weighted : 0.706, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 601, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.709, Val AUC_ROC Weighted : 0.709, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 701, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.711, Val AUC_ROC Weighted : 0.711, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 801, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.712, Val AUC_ROC Weighted : 0.712, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 901, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.712, Val AUC_ROC Weighted : 0.712, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 1001, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.713, Val AUC_ROC Weighted : 0.713, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "\n",
      "\n",
      "-----------LSTMs Variable Length Input--------------\n",
      "Epoch: 1, Train loss: 0.683, Val loss: 0.676, Val Acc: 0.530, Val AUC_ROC Macro: 0.501, Val AUC_ROC Weighted : 0.501, Val Recall Macro: 0.498, Val Precision Weighted : 0.957, Val Ham Loss : 0.470\n",
      "Epoch: 101, Train loss: 0.011, Val loss: 0.011, Val Acc: 0.978, Val AUC_ROC Macro: 0.488, Val AUC_ROC Weighted : 0.488, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 201, Train loss: 0.009, Val loss: 0.010, Val Acc: 0.978, Val AUC_ROC Macro: 0.487, Val AUC_ROC Weighted : 0.487, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 301, Train loss: 0.009, Val loss: 0.009, Val Acc: 0.978, Val AUC_ROC Macro: 0.487, Val AUC_ROC Weighted : 0.487, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 401, Train loss: 0.008, Val loss: 0.009, Val Acc: 0.978, Val AUC_ROC Macro: 0.488, Val AUC_ROC Weighted : 0.488, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 501, Train loss: 0.008, Val loss: 0.009, Val Acc: 0.978, Val AUC_ROC Macro: 0.490, Val AUC_ROC Weighted : 0.490, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 601, Train loss: 0.008, Val loss: 0.009, Val Acc: 0.978, Val AUC_ROC Macro: 0.491, Val AUC_ROC Weighted : 0.491, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 701, Train loss: 0.008, Val loss: 0.009, Val Acc: 0.978, Val AUC_ROC Macro: 0.492, Val AUC_ROC Weighted : 0.492, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 801, Train loss: 0.008, Val loss: 0.009, Val Acc: 0.978, Val AUC_ROC Macro: 0.492, Val AUC_ROC Weighted : 0.492, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 901, Train loss: 0.008, Val loss: 0.009, Val Acc: 0.978, Val AUC_ROC Macro: 0.493, Val AUC_ROC Weighted : 0.493, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 1001, Train loss: 0.008, Val loss: 0.009, Val Acc: 0.978, Val AUC_ROC Macro: 0.493, Val AUC_ROC Weighted : 0.493, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "\n",
      "\n",
      "-----------LSTMs with Glove Representation of Input--------------\n",
      "Epoch: 1, Train loss: 0.682, Val loss: 0.674, Val Acc: 0.579, Val AUC_ROC Macro: 0.523, Val AUC_ROC Weighted : 0.523, Val Recall Macro: 0.528, Val Precision Weighted : 0.959, Val Ham Loss : 0.421\n",
      "Epoch: 101, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.614, Val AUC_ROC Weighted : 0.614, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 201, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.657, Val AUC_ROC Weighted : 0.657, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 301, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.679, Val AUC_ROC Weighted : 0.679, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 401, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.698, Val AUC_ROC Weighted : 0.698, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 501, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.710, Val AUC_ROC Weighted : 0.710, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 601, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.711, Val AUC_ROC Weighted : 0.711, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 701, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.712, Val AUC_ROC Weighted : 0.712, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 801, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.712, Val AUC_ROC Weighted : 0.712, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 901, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.711, Val AUC_ROC Weighted : 0.711, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n",
      "Epoch: 1001, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.711, Val AUC_ROC Weighted : 0.711, Val Recall Macro: 0.500, Val Precision Weighted : 0.957, Val Ham Loss : 0.022\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
